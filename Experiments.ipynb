{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9522670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96046edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.6.0-cp39-cp39-win_amd64.whl (12.3 MB)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.9-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.12-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.7-cp39-cp39-win_amd64.whl (483 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.10-cp39-cp39-win_amd64.whl (7.4 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: typing-extensions, colorama, catalogue, srsly, pydantic, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "Successfully installed blis-0.7.10 catalogue-2.0.9 colorama-0.4.6 confection-0.1.0 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.2 preshed-3.0.8 pydantic-1.10.12 smart-open-6.3.0 spacy-3.6.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.7 thinc-8.1.10 typer-0.9.0 typing-extensions-4.7.1 wasabi-1.1.2\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225e655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence: I dislike this product\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "#1.Write an NLP Code to classify a text as positive/negative sentiment.\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "# Preprocess the user input\n",
    "def extract_words(text):\n",
    "    return dict((word, True) for word in text.lower().split())\n",
    "\n",
    "# Prepare your own positive and negative sentence examples\n",
    "positive_samples = [\n",
    "    (\"I love this product!\", \"Positive\"),\n",
    "    (\"This is amazing!\", \"Positive\"),\n",
    "    # Add more positive examples\n",
    "]\n",
    "\n",
    "negative_samples = [\n",
    "    (\"This is terrible!\", \"Negative\"),\n",
    "    (\"I dislike it.\", \"Negative\"),\n",
    "    # Add more negative examples\n",
    "]\n",
    "\n",
    "# Combine positive and negative samples into the training set\n",
    "train_set = [(extract_words(sentence), sentiment) for sentence, sentiment in positive_samples + negative_samples]\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"Enter a sentence: \")\n",
    "sentiment = classifier.classify(extract_words(user_input))\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ada246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text: how\n",
      "Detected language: en\n"
     ]
    }
   ],
   "source": [
    "#3.Write an NLP code to find the language of given text.\n",
    "def detect_language(text):\n",
    "    # Define common words for different languages\n",
    "    common_words = {\n",
    "        'en': {'hello', 'world', 'how', 'are', 'you'},\n",
    "        'es': {'hola', 'mundo', 'cómo', 'estás'},\n",
    "        # Add more common words for other languages as needed\n",
    "    }\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = set(text.lower().split())\n",
    "\n",
    "    # Find the language with the most common words\n",
    "    detected_language = max(common_words, key=lambda lang: len(common_words[lang] & words))\n",
    "\n",
    "    return detected_language\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"Enter a text: \")\n",
    "language = detect_language(user_input)\n",
    "print(f\"Detected language: {language}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170025ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (58.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (21.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.11.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 21:30:00.578664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-07-31 21:30:00.578831: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-31 21:30:04.859184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-07-31 21:30:04.859539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2023-07-31 21:30:04.859873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2023-07-31 21:30:04.860214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2023-07-31 21:30:04.860546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2023-07-31 21:30:04.860868: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2023-07-31 21:30:04.861185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2023-07-31 21:30:04.861529: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2023-07-31 21:30:04.861546: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\parkkavan\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.6.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9fd9763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text: My name is Billa, I am 23 years old.\n",
      "Preprocessed text: Billa 23 year old\n"
     ]
    }
   ],
   "source": [
    "#5. Write an NLP code to preprocess a given text.\n",
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Remove punctuation, stopwords, and lemmatize the tokens\n",
    "    words = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "\n",
    "    # Join the words back into a preprocessed text\n",
    "    preprocessed_text = \" \".join(words)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"Enter a text: \")\n",
    "preprocessed_text = preprocess_text(user_input)\n",
    "print(f\"Preprocessed text: {preprocessed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75bd0a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Transformers?\n",
      "Answer: Transformers is a natural language processing library released by Hugging Face.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PARKKA~1\\AppData\\Local\\Temp/ipykernel_23020/1541040770.py:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_scores = [question_doc.similarity(sentence) for sentence in context_doc.sents]\n"
     ]
    }
   ],
   "source": [
    "#7. Write an NLP code to create a Question-Answering system from given context.\n",
    "import spacy\n",
    "\n",
    "def extract_answer(question, context):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    context_doc = nlp(context)\n",
    "    question_doc = nlp(question)\n",
    "\n",
    "    # Compute the similarity scores between the question and each sentence in the context\n",
    "    similarity_scores = [question_doc.similarity(sentence) for sentence in context_doc.sents]\n",
    "\n",
    "    # Find the index of the most relevant sentence based on similarity\n",
    "    max_similarity_idx = similarity_scores.index(max(similarity_scores))\n",
    "\n",
    "    # Return the most relevant sentence as the answer\n",
    "    return list(context_doc.sents)[max_similarity_idx].text.strip()\n",
    "\n",
    "# Example usage\n",
    "context = \"\"\"\n",
    "    Transformers is a natural language processing library released by Hugging Face.\n",
    "    It provides an easy-to-use API to use pre-trained language models for various NLP tasks.\n",
    "    The `transformers` library supports a wide range of models and tasks, including question-answering.\n",
    "\"\"\"\n",
    "\n",
    "question = \"What is Transformers?\"\n",
    "\n",
    "answer = extract_answer(question, context)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96fe4a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the use of Transformers?\n",
      "Answer: The `transformers` library supports a wide range of models and tasks, including question-answering.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PARKKA~1\\AppData\\Local\\Temp/ipykernel_23020/1541040770.py:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_scores = [question_doc.similarity(sentence) for sentence in context_doc.sents]\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the use of Transformers?\"\n",
    "\n",
    "answer = extract_answer(question, context)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0421840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Airline Ticket Booking Chatbot!\n",
      "Destinations:\n",
      "1. New York\n",
      "2. Los Angeles\n",
      "3. Chicago\n",
      "4. San Francisco\n",
      "Enter the destination number you want to fly to: 1\n",
      "You have selected New York as your destination.\n",
      "When do you want to depart? (YYYY-MM-DD): 2023-12-11\n",
      "When do you want to return? (YYYY-MM-DD): 2023-12-31\n",
      "How many passengers will be traveling? 2\n",
      "\n",
      "Booking Summary:\n",
      "Destination: New York\n",
      "Departure Date: 2023-12-11\n",
      "Return Date: 2023-12-31\n",
      "Passenger Count: 2\n",
      "Your flight has been booked. Have a great trip!\n"
     ]
    }
   ],
   "source": [
    "#2. Create a chatbot for booking airline tickets.\n",
    "print(\"Welcome to the Airline Ticket Booking Chatbot!\")\n",
    "\n",
    "destinations = {\n",
    "    1: \"New York\",\n",
    "    2: \"Los Angeles\",\n",
    "    3: \"Chicago\",\n",
    "    4: \"San Francisco\"\n",
    "}\n",
    "\n",
    "print(\"Destinations:\")\n",
    "for key, destination in destinations.items():\n",
    "    print(f\"{key}. {destination}\")\n",
    "\n",
    "choice = int(input(\"Enter the destination number you want to fly to: \"))\n",
    "while choice not in destinations.keys():\n",
    "    print(\"Invalid choice. Please enter a valid option.\")\n",
    "    choice = int(input(\"Enter the destination number you want to fly to: \"))\n",
    "\n",
    "destination = destinations[choice]\n",
    "print(f\"You have selected {destination} as your destination.\")\n",
    "\n",
    "departure_date = input(\"When do you want to depart? (YYYY-MM-DD): \")\n",
    "\n",
    "return_date = input(\"When do you want to return? (YYYY-MM-DD): \")\n",
    "\n",
    "passenger_count = int(input(\"How many passengers will be traveling? \"))\n",
    "\n",
    "print(\"\\nBooking Summary:\")\n",
    "print(f\"Destination: {destination}\")\n",
    "print(f\"Departure Date: {departure_date}\")\n",
    "print(f\"Return Date: {return_date}\")\n",
    "print(f\"Passenger Count: {passenger_count}\")\n",
    "\n",
    "# Add the code here to actually book the flight (e.g., connect to an airline API or a booking service).\n",
    "\n",
    "print(\"Your flight has been booked. Have a great trip!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "690b182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GiftBot: Hi! I'm GiftBot. I can help you find the perfect gift for any occasion. How can I assist you today?\n",
      "You: recommend\n",
      "GiftBot: I recommend gifting a Personalized photo frame\n",
      "You: recommend\n",
      "GiftBot: I recommend gifting a Hats\n",
      "You: bye\n",
      "GiftBot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "#8. Create a chatbot for recommending fashion accessories.\n",
    "import random\n",
    "\n",
    "fashion_accessories = [\n",
    "    \"Wristwatch\", \"Perfume\", \"Wallet\", \"Jewelry\", \"Sunglasses\", \"Personalized photo frame\",\n",
    "    \"Scarves\", \"Handbags\", \"Ties\", \"Hats\", \"Belts\", \"Gloves\"\n",
    "]\n",
    "\n",
    "print(\"GiftBot: Hi! I'm GiftBot. I can help you find the perfect gift for any occasion. How can I assist you today?\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"recommend\":\n",
    "        # Generate a random fashion accessory recommendation\n",
    "        recommended_accessory = random.choice(fashion_accessories)\n",
    "        print(\"GiftBot: I recommend gifting a\", recommended_accessory)\n",
    "    elif user_input.lower() == \"bye\":\n",
    "        print(\"GiftBot: Goodbye!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"GiftBot: I'm sorry, I didn't understand. Can you please rephrase your request?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfd188fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to MovieTicketBot!\n",
      "Movie options:\n",
      "1. Movie A\n",
      "2. Movie B\n",
      "3. Movie C\n",
      "Enter the movie number you want to watch:A\n",
      "Invalid input. Please try again.\n",
      "Enter the movie number you want to watch:1\n",
      "Enter the date of the movie (e.g., 2023-08-01):2023-08-03\n",
      "Enter the time of the movie (e.g., 15:30):16:00\n",
      "Ticket Categories:\n",
      "1. Standard (Rs. 150)\n",
      "2. Premium (Rs. 200)\n",
      "3. VIP (Rs. 250)\n",
      "Select the ticket category (1/2/3):3\n",
      "Enter the number of tickets you want to book:2\n",
      "Thank you for providing the details.\n",
      "Booking Summary:\n",
      "Movie: Movie A\n",
      "Date: 2023-08-03\n",
      "Time: 16:00\n",
      "Ticket Category: VIP\n",
      "Number of Tickets: 2\n",
      "Total Amount: Rs. 500\n",
      "Enjoy the movie!\n"
     ]
    }
   ],
   "source": [
    "#6. Create a chatbot for booking movie tickets.\n",
    "def get_user_input(prompt, options=None):\n",
    "    while True:\n",
    "        user_input = input(prompt).strip().lower()\n",
    "        if options is not None and user_input not in options:\n",
    "            print(\"Invalid input. Please try again.\")\n",
    "        else:\n",
    "            return user_input\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to MovieTicketBot!\")\n",
    "    print(\"Movie options:\")\n",
    "    print(\"1. Movie A\")\n",
    "    print(\"2. Movie B\")\n",
    "    print(\"3. Movie C\")\n",
    "    movie_options = [\"1\", \"2\", \"3\"]\n",
    "\n",
    "    movie_choice = get_user_input(\"Enter the movie number you want to watch:\", movie_options)\n",
    "    movie_names = {\n",
    "        \"1\": \"Movie A\",\n",
    "        \"2\": \"Movie B\",\n",
    "        \"3\": \"Movie C\"\n",
    "    }\n",
    "    selected_movie = movie_names[movie_choice]\n",
    "\n",
    "    # Add more questions about date, time, theater, seat selection, etc.\n",
    "    # For simplicity, we'll just ask for the date, time, and number of tickets.\n",
    "\n",
    "    date = get_user_input(\"Enter the date of the movie (e.g., 2023-08-01):\")\n",
    "    time = get_user_input(\"Enter the time of the movie (e.g., 15:30):\")\n",
    "\n",
    "    print(\"Ticket Categories:\")\n",
    "    print(\"1. Standard (Rs. 150)\")\n",
    "    print(\"2. Premium (Rs. 200)\")\n",
    "    print(\"3. VIP (Rs. 250)\")\n",
    "    category_options = [\"1\", \"2\", \"3\"]\n",
    "\n",
    "    category_choice = get_user_input(\"Select the ticket category (1/2/3):\", category_options)\n",
    "    ticket_categories = {\n",
    "        \"1\": {\"name\": \"Standard\", \"price\": 150},\n",
    "        \"2\": {\"name\": \"Premium\", \"price\": 200},\n",
    "        \"3\": {\"name\": \"VIP\", \"price\": 250}\n",
    "    }\n",
    "    selected_category = ticket_categories[category_choice]\n",
    "\n",
    "    ticket_quantity = get_user_input(\"Enter the number of tickets you want to book:\", options=None)\n",
    "    while not ticket_quantity.isdigit() or int(ticket_quantity) <= 0:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "        ticket_quantity = get_user_input(\"Enter the number of tickets you want to book:\", options=None)\n",
    "\n",
    "    ticket_quantity = int(ticket_quantity)\n",
    "\n",
    "    # Calculate the total amount to be paid\n",
    "    total_amount = selected_category[\"price\"] * ticket_quantity\n",
    "\n",
    "    print(\"Thank you for providing the details.\")\n",
    "    print(\"Booking Summary:\")\n",
    "    print(f\"Movie: {selected_movie}\")\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"Time: {time}\")\n",
    "    print(f\"Ticket Category: {selected_category['name']}\")\n",
    "    print(f\"Number of Tickets: {ticket_quantity}\")\n",
    "    print(f\"Total Amount: Rs. {total_amount}\")\n",
    "    print(\"Enjoy the movie!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf65b56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to PizzaBot!\n",
      "Pizza Menu:\n",
      "1. Margherita\n",
      "2. Pepperoni\n",
      "3. Veggie Delight\n",
      "4. Cheese Burst\n",
      "Enter the pizza number you want to order:1\n",
      "You have selected Margherita.\n",
      "Enter the size you want (Small, Medium, Large):Large\n",
      "Enter the quantity:3\n",
      "Your order: Large Margherita x 3\n"
     ]
    }
   ],
   "source": [
    "#4. Create a chatbot for accepting and processing pizza order.\n",
    "print(\"Welcome to PizzaBot!\")\n",
    "print(\"Pizza Menu:\")\n",
    "print(\"1. Margherita\")\n",
    "print(\"2. Pepperoni\")\n",
    "print(\"3. Veggie Delight\")\n",
    "print(\"4. Cheese Burst\")\n",
    "\n",
    "choice = int(input(\"Enter the pizza number you want to order:\"))\n",
    "while choice not in [1, 2, 3, 4]:\n",
    "    print(\"Invalid choice. Please enter a valid option.\")\n",
    "    choice = int(input(\"Enter the pizza number you want to order:\"))\n",
    "\n",
    "pizza_names = {\n",
    "    1: \"Margherita\",\n",
    "    2: \"Pepperoni\",\n",
    "    3: \"Veggie Delight\",\n",
    "    4: \"Cheese Burst\"\n",
    "}\n",
    "\n",
    "pizza = pizza_names[choice]\n",
    "print(f\"You have selected {pizza}.\")\n",
    "\n",
    "size = input(\"Enter the size you want (Small, Medium, Large):\").strip().lower()\n",
    "while size not in [\"small\", \"medium\", \"large\"]:\n",
    "    print(\"Invalid size. Please enter a valid size.\")\n",
    "    size = input(\"Enter the size you want (Small, Medium, Large):\").strip().lower()\n",
    "\n",
    "quantity = int(input(\"Enter the quantity:\"))\n",
    "while quantity <= 0:\n",
    "    print(\"Invalid quantity. Please enter a valid quantity.\")\n",
    "    quantity = int(input(\"Enter the quantity:\"))\n",
    "\n",
    "print(f\"Your order: {size.capitalize()} {pizza} x {quantity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640d437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
